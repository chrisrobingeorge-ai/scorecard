# overall_scorecard_app.py
#
# Purpose:
#   Take the department scorecard PDFs from the Monthly Scorecard app,
#   extract their embedded JSON, and generate an organisation-wide
#   Board narrative + PDF.
#
#   This app:
#   - Shows a simple table of which departments/months you’ve loaded
#   - Calls ai_utils.interpret_overall_scorecards(...) for the AI summary
#   - Uses pdf_utils.build_overall_board_pdf(...) to create a Board PDF

from __future__ import annotations

import json
from typing import Dict, Any, List

import pandas as pd
import streamlit as st
from PyPDF2 import PdfReader

from ai_utils import interpret_overall_scorecards
from pdf_utils import build_overall_board_pdf

JSON_PREFIX = "AB_SCORECARD_JSON:"

# ─────────────────────────────────────────────────────────────────────────────
# Streamlit page config
# ─────────────────────────────────────────────────────────────────────────────
st.set_page_config(page_title="Overall Monthly Scorecard – Board Report", layout="wide")

st.title("Overall Monthly Scorecard – Board Narrative")

st.write(
    """
Upload the **department scorecard PDFs** generated by the Monthly Scorecard app.  
This helper will extract their embedded summaries and generate a single,
organisation-wide Board report (and a downloadable PDF).
"""
)

# ─────────────────────────────────────────────────────────────────────────────
# Helper: extract a structured summary from one payload
# ─────────────────────────────────────────────────────────────────────────────
def extract_department_summary(
    payload: Dict[str, Any],
    source_name: str,
) -> Dict[str, Any]:
    """
    Take the JSON payload embedded in a scorecard PDF and distill the
    key bits we need for an organisation-wide narrative.

    We intentionally keep this simple:
    - Which department and month?
    - What is the overall score?
    - What are the pillar scores (if present)?
    - What is the department-level AI summary text?
    """
    meta = payload.get("meta", {}) or {}
    scores = payload.get("scores", {}) or {}
    ai_interp = payload.get("ai_interpretation", {}) or {}
    questions = payload.get("questions", []) or []

    department = meta.get("department") or meta.get("dept_label") or ""
    month = meta.get("month")
    month_label = meta.get("month_label") or month
    production = meta.get("production") or meta.get("programme") or ""
    staff_name = meta.get("staff_name") or ""
    role = meta.get("role") or ""

    overall_score = scores.get("overall_score")
    pillar_scores = scores.get("pillar_scores") or {}

    summary_text = ai_interp.get("overall_summary") or ""

    return {
        "source_file": source_name,
        "department": department,
        "month": month,
        "month_label": month_label,
        "overall_score": overall_score,
        "pillar_scores": pillar_scores,
        "production": production,
        "staff_name": staff_name,
        "role": role,
        "num_questions": len(questions),
        "summary_text": summary_text,
    }


# ─────────────────────────────────────────────────────────────────────────────
# 1. Upload PDFs
# ─────────────────────────────────────────────────────────────────────────────
uploaded_files = st.file_uploader(
    "Upload department scorecard PDFs (you can select multiple)",
    type=["pdf"],
    accept_multiple_files=True,
)

if not uploaded_files:
    st.stop()

# ─────────────────────────────────────────────────────────────────────────────
# 2. Extract JSON from each PDF and build department summaries
# ─────────────────────────────────────────────────────────────────────────────
dept_summaries: List[Dict[str, Any]] = []
skipped_files: List[str] = []

for f in uploaded_files:
    try:
        reader = PdfReader(f)
    except Exception:
        skipped_files.append(f.name)
        continue

    info = reader.metadata or {}
    subject = getattr(info, "subject", None) or info.get("/Subject") or ""

    if not subject or JSON_PREFIX not in subject:
        skipped_files.append(f.name)
        continue

    try:
        _, json_str = subject.split(JSON_PREFIX, 1)
        payload = json.loads(json_str)
    except Exception:
        skipped_files.append(f.name)
        continue

    dept_summary = extract_department_summary(payload, f.name)
    dept_summaries.append(dept_summary)

if not dept_summaries:
    st.error("No usable embedded scorecard data found in the uploaded PDFs.")
    if skipped_files:
        st.info("Files skipped (no or invalid embedded JSON): " + ", ".join(skipped_files))
    st.stop()

if skipped_files:
    st.warning(
        "Some files were skipped because they did not contain embedded scorecard data: "
        + ", ".join(skipped_files)
    )

# ─────────────────────────────────────────────────────────────────────────────
# 3. Sanity table – what did we load?
# ─────────────────────────────────────────────────────────────────────────────
df_overview = pd.DataFrame(
    [
        {
            "source_file": ds["source_file"],
            "department": ds["department"],
            "month_label": ds["month_label"],
            "overall_score": ds["overall_score"],
            "num_questions": ds["num_questions"],
        }
        for ds in dept_summaries
    ]
)

st.subheader("Loaded department scorecards")
st.dataframe(df_overview, use_container_width=True)

# Infer a reporting label (e.g., a single month, or multiple)
unique_months = df_overview["month_label"].dropna().unique().tolist()
if len(unique_months) == 1:
    reporting_label = unique_months[0]
elif len(unique_months) > 1:
    reporting_label = ", ".join(unique_months)
else:
    reporting_label = "Multiple periods"

st.markdown(f"**Reporting period (inferred):** {reporting_label}")

# ─────────────────────────────────────────────────────────────────────────────
# 4. Generate Board narrative via AI + PDF
# ─────────────────────────────────────────────────────────────────────────────
st.subheader("Board narrative")

if st.button("Generate Board Narrative with AI"):
    with st.spinner("Generating Board narrative..."):
        ai_result = interpret_overall_scorecards(dept_summaries)

    board_report = (ai_result.get("overall_summary") or "").strip()
    prompt_used = ai_result.get("prompt", "")

    if not board_report:
        st.error("AI did not return a Board report. Check ai_utils.interpret_overall_scorecards.")
    else:
        st.markdown("### Draft Board Report")
        st.markdown(board_report)

        # Build a Board PDF
        pdf_bytes = build_overall_board_pdf(
            reporting_label=reporting_label,
            dept_overview=df_overview,
            ai_result=ai_result,
            logo_path=None,  # if you have a logo file, put the path here
        )

        st.download_button(
            label="Download Board Report PDF",
            data=pdf_bytes,
            file_name=f"overall_board_report_{reporting_label.replace(' ', '_')}.pdf",
            mime="application/pdf",
        )

        # Optional: show the exact AI prompt used (for auditing / debugging)
        with st.expander("Show AI prompt used"):
            st.code(prompt_used, language="markdown")
