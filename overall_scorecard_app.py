# overall_scorecard_app.py
#
# Purpose:
#   Take the department scorecard PDFs from the Monthly Scorecard app,
#   extract their embedded JSON, and generate an organisation-wide
#   Board narrative + PDF.
#
#   This app:
#   - Shows a simple table of which departments/months youâ€™ve loaded
#   - Calls ai_utils.interpret_overall_scorecards(...) for the AI summary
#   - Lets you EDIT the AI text before exporting
#   - Uses pdf_utils.build_overall_board_pdf(...) to create a Board PDF

from __future__ import annotations

import json
from typing import Dict, Any, List

import pandas as pd
import streamlit as st
from PyPDF2 import PdfReader

from ai_utils import interpret_overall_scorecards
from pdf_utils import build_overall_board_pdf
from docx_utils import build_overall_board_docx

JSON_PREFIX = "AB_SCORECARD_JSON:"

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Streamlit page config
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(page_title="Overall Monthly Scorecard â€“ Board Report", layout="wide")

st.title("Overall Monthly Scorecard â€“ Board Narrative")

st.write(
    """
Upload the **department scorecard PDFs** generated by the Monthly Scorecard app.  
This helper will extract their embedded summaries and generate a single,
organisation-wide Board report (and a downloadable PDF).
"""
)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Helper: extract a structured summary from one payload
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def extract_department_summary(
    payload: Dict[str, Any],
    source_name: str,
) -> Dict[str, Any]:
    """
    Take the JSON payload embedded in a scorecard PDF and distill the
    key bits we need for an organisation-wide narrative.
    """
    meta = payload.get("meta", {}) or {}
    scores = payload.get("scores", {}) or {}
    ai_interp = payload.get("ai_interpretation", {}) or {}
    questions = payload.get("questions", []) or []

    department = meta.get("department") or meta.get("dept_label") or ""
    month = meta.get("month")
    month_label = meta.get("month_label") or month
    production = meta.get("production") or meta.get("programme") or ""
    staff_name = meta.get("staff_name") or ""
    role = meta.get("role") or ""

    overall_score = scores.get("overall_score")
    pillar_scores = scores.get("pillar_scores") or {}

    summary_text = ai_interp.get("overall_summary") or ""

    return {
        "source_file": source_name,
        "department": department,
        "month": month,
        "month_label": month_label,
        "overall_score": overall_score,
        "pillar_scores": pillar_scores,
        "production": production,
        "staff_name": staff_name,
        "role": role,
        "num_questions": len(questions),
        "summary_text": summary_text,
    }


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 1. Upload PDFs
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
uploaded_files = st.file_uploader(
    "Upload department scorecard PDFs (you can select multiple)",
    type=["pdf"],
    accept_multiple_files=True,
)

if not uploaded_files:
    st.stop()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 2. Extract JSON from each PDF and build department summaries
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
dept_summaries: List[Dict[str, Any]] = []
skipped_files: List[str] = []

for f in uploaded_files:
    try:
        reader = PdfReader(f)
    except Exception:
        skipped_files.append(f.name)
        continue

    info = reader.metadata or {}
    subject = getattr(info, "subject", None) or info.get("/Subject") or ""

    if not subject or JSON_PREFIX not in subject:
        skipped_files.append(f.name)
        continue

    try:
        _, json_str = subject.split(JSON_PREFIX, 1)
        payload = json.loads(json_str)
    except Exception:
        skipped_files.append(f.name)
        continue

    dept_summary = extract_department_summary(payload, f.name)
    dept_summaries.append(dept_summary)

if not dept_summaries:
    st.error("No usable embedded scorecard data found in the uploaded PDFs.")
    if skipped_files:
        st.info("Files skipped (no or invalid embedded JSON): " + ", ".join(skipped_files))
    st.stop()

if skipped_files:
    st.warning(
        "Some files were skipped because they did not contain embedded scorecard data: "
        + ", ".join(skipped_files)
    )

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 3. Sanity table â€“ what did we load?
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
df_overview = pd.DataFrame(
    [
        {
            "source_file": ds["source_file"],
            "department": ds["department"],
            "month_label": ds["month_label"],
            "overall_score": ds["overall_score"],
            "num_questions": ds["num_questions"],
        }
        for ds in dept_summaries
    ]
)

st.subheader("Loaded department scorecards")
st.dataframe(df_overview, use_container_width=True)

# Infer a reporting label (e.g., a single month, or multiple)
unique_months = df_overview["month_label"].dropna().unique().tolist()
if len(unique_months) == 1:
    reporting_label = unique_months[0]
elif len(unique_months) > 1:
    reporting_label = ", ".join(unique_months)
else:
    reporting_label = "Multiple periods"

st.markdown(f"**Reporting period (inferred):** {reporting_label}")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 4. Board-level AI Interpretation (fully editable)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.subheader("Board Interpretation (editable)")

# Initialise cached AI result for the overall Board report
if "overall_ai_result" not in st.session_state:
    st.session_state["overall_ai_result"] = None

# Helper normalisers (parallel to main app, but simplified for Board layer)
def _normalise_overall(val: Any) -> str:
    """Turn overall_summary (string / list / dict) into a single editable string."""
    if isinstance(val, list):
        parts = []
        for v in val:
            if isinstance(v, dict) and "text" in v:
                parts.append(str(v["text"]))
            else:
                parts.append(str(v))
        return "\n\n".join(p for p in parts if str(p).strip())
    if isinstance(val, dict) and "text" in val:
        return str(val["text"])
    return str(val or "")

def _normalise_list(val: Any) -> str:
    """Turn list-like fields (risks, priorities) into newline-separated text."""
    if not val:
        return ""
    if isinstance(val, list):
        return "\n".join(str(x) for x in val if str(x).strip())
    return str(val or "")

# Button to (re)generate the Board-level AI interpretation
if st.button("Generate / Refresh Board Narrative with AI"):
    try:
        with st.spinner("Generating Board-level narrative from departmental summaries..."):
            ai_result = interpret_overall_scorecards(dept_summaries)
    except RuntimeError as e:
        st.error(f"AI configuration error: {e}")
        st.info(
            "Check your OPENAI_API_KEY secret and that `openai>=1.51.0` "
            "(or newer) is in requirements.txt."
        )
        st.stop()
    except Exception as e:
        st.error(f"Failed to generate Board report: {e}")
        st.stop()

    st.success("Board-level AI report generated.")
    st.session_state["overall_ai_result"] = ai_result

overall_ai_result = st.session_state["overall_ai_result"]

if overall_ai_result is None:
    st.info("Click **Generate / Refresh Board Narrative with AI** to create the report.")
else:
    ai_result = overall_ai_result  # local alias for easier mutation

    # â”€â”€ Helper functions for consolidated editor â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def _build_consolidated_summary():
        """Build a single text representation of the entire Board AI summary."""
        parts = []
        
        # Board Narrative
        parts.append("=== BOARD NARRATIVE ===")
        raw_overall = ai_result.get("overall_summary", "")
        default_overall = _normalise_overall(raw_overall)
        parts.append(default_overall)
        parts.append("")
        
        # Strategic Pillars
        pillar_summaries = ai_result.get("pillar_summaries", []) or []
        if pillar_summaries:
            parts.append("=== STRATEGIC PILLARS ===")
            for ps in pillar_summaries:
                pillar_label = ps.get("strategic_pillar", "Pillar") or "Pillar"
                summary_val = str(ps.get("summary", "") or "")
                parts.append(f"--- {pillar_label} ---")
                parts.append(summary_val)
                parts.append("")
        
        # Risks
        parts.append("=== STRATEGIC PILLAR RISKS / CONCERNS ===")
        risks_raw = ai_result.get("risks", []) or []
        risks_default = _normalise_list(risks_raw)
        parts.append(risks_default)
        parts.append("")
        
        # Priorities
        parts.append("=== ORGANISATION-WIDE PRIORITIES FOR NEXT PERIOD ===")
        priorities_raw = ai_result.get("priorities_next_month", []) or []
        priorities_default = _normalise_list(priorities_raw)
        parts.append(priorities_default)
        parts.append("")
        
        # Notes for leadership
        parts.append("=== NOTES FOR LEADERSHIP ===")
        nfl_raw = ai_result.get("notes_for_leadership", "") or ""
        parts.append(str(nfl_raw))
        
        return "\n".join(parts)
    
    def _parse_consolidated_summary(text: str):
        """Parse the consolidated text back into the ai_result structure."""
        # Split into major sections using the === markers
        sections = {}
        current_section = None
        current_content = []
        
        for line in text.split('\n'):
            # Check for main section headers
            if line.strip().startswith('=== ') and line.strip().endswith(' ==='):
                if current_section:
                    sections[current_section] = '\n'.join(current_content).strip()
                current_section = line.strip()[4:-4].strip()
                current_content = []
            else:
                current_content.append(line)
        
        # Don't forget the last section
        if current_section:
            sections[current_section] = '\n'.join(current_content).strip()
        
        # Parse Board Narrative
        if 'BOARD NARRATIVE' in sections:
            ai_result["overall_summary"] = sections['BOARD NARRATIVE']
        
        # Parse Strategic Pillars
        if 'STRATEGIC PILLARS' in sections:
            pillar_text = sections['STRATEGIC PILLARS']
            # Split by the --- markers for each pillar
            pillar_blocks = []
            current_pillar = []
            for line in pillar_text.split('\n'):
                if line.strip().startswith('---') and line.strip().endswith('---'):
                    if current_pillar:
                        pillar_blocks.append('\n'.join(current_pillar).strip())
                    current_pillar = [line]
                else:
                    current_pillar.append(line)
            if current_pillar:
                pillar_blocks.append('\n'.join(current_pillar).strip())
            
            pillar_summaries = ai_result.get("pillar_summaries", []) or []
            
            for i, block in enumerate(pillar_blocks):
                if not block.strip() or i >= len(pillar_summaries):
                    continue
                
                # Split header from content
                lines = block.split('\n', 1)
                if len(lines) < 2:
                    continue
                    
                header = lines[0].strip()
                summary_text = lines[1].strip() if len(lines) > 1 else ""
                
                # Extract pillar name from header (format: "--- Pillar Name ---")
                pillar_name = header.strip('-').strip()
                
                # Update the pillar
                pillar_summaries[i]["strategic_pillar"] = pillar_name
                pillar_summaries[i]["summary"] = summary_text
        
        # Parse Risks
        if 'STRATEGIC PILLAR RISKS / CONCERNS' in sections:
            risks_text = sections['STRATEGIC PILLAR RISKS / CONCERNS']
            ai_result["risks"] = [
                line.strip() for line in risks_text.splitlines() if line.strip()
            ]
        
        # Parse Priorities
        if 'ORGANISATION-WIDE PRIORITIES FOR NEXT PERIOD' in sections:
            priorities_text = sections['ORGANISATION-WIDE PRIORITIES FOR NEXT PERIOD']
            ai_result["priorities_next_month"] = [
                line.strip() for line in priorities_text.splitlines() if line.strip()
            ]
        
        # Parse Notes for Leadership
        if 'NOTES FOR LEADERSHIP' in sections:
            ai_result["notes_for_leadership"] = sections['NOTES FOR LEADERSHIP']

    # â”€â”€ Consolidated AI Summary Editor â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    st.markdown("### Draft Board Report (Consolidated Editor)")
    st.info(
        "Edit all sections in one box below. The sections are marked with "
        "`=== SECTION NAME ===` headers. When done, changes are automatically saved."
    )
    
    consolidated_text = _build_consolidated_summary()
    
    edited_consolidated = st.text_area(
        "Board report (all sections):",
        value=consolidated_text,
        height=600,
        key="board_consolidated_editor",
    )
    
    # Parse the edited text back into ai_result
    _parse_consolidated_summary(edited_consolidated)

    # Persist the edited result back to session_state
    st.session_state["overall_ai_result"] = ai_result

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # 4.5. Save AI summary as JSON
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if st.session_state.get("overall_ai_result"):
        ai_summary_payload = {
            "reporting_label": reporting_label,
            "dept_summaries": dept_summaries,
            "ai_result": st.session_state["overall_ai_result"],
        }
        st.sidebar.download_button(
            "ğŸ’¾ Save AI summary only (JSON)",
            data=json.dumps(ai_summary_payload, indent=2),
            file_name=f"overall_ai_summary_{reporting_label.replace(' ', '_')}.json",
            mime="application/json",
            help="Just the edited AI summary for the overall Board report.",
        )

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # 5. Build and download the Board Report (PDF and DOCX)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    st.subheader("Export Board Report")
    
    col1, col2 = st.columns(2)
    
    with col1:
        pdf_bytes = build_overall_board_pdf(
            reporting_label=reporting_label,
            dept_overview=df_overview,
            ai_result=ai_result,
            logo_path="assets/alberta_ballet_logo.png",  # adjust if needed
        )

        st.download_button(
            label="ğŸ“„ Download Board Report PDF",
            data=pdf_bytes,
            file_name=f"overall_board_report_{reporting_label.replace(' ', '_')}.pdf",
            mime="application/pdf",
        )
    
    with col2:
        docx_bytes = build_overall_board_docx(
            reporting_label=reporting_label,
            dept_overview=df_overview,
            ai_result=ai_result,
            logo_path="assets/alberta_ballet_logo.png",  # adjust if needed
        )

        st.download_button(
            label="ğŸ“ Download Board Report DOCX",
            data=docx_bytes,
            file_name=f"overall_board_report_{reporting_label.replace(' ', '_')}.docx",
            mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document",
        )
