# overall_scorecard_app.py

import json
from typing import Dict, Any, List

import pandas as pd
import streamlit as st
from PyPDF2 import PdfReader

JSON_PREFIX = "AB_SCORECARD_JSON:"

st.set_page_config(page_title="Overall Monthly Scorecard Summary", layout="wide")

st.title("Overall Monthly Scorecard Summary")

st.write("Upload the department scorecard PDFs generated by the Monthly Scorecard app.")


# ─────────────────────────────────────────────────────────────────────────────
# Helper: flatten a single PDF payload into rows
# ─────────────────────────────────────────────────────────────────────────────
def flatten_payload_to_rows(
    payload: Dict[str, Any],
    source_name: str,
) -> List[Dict[str, Any]]:
    """
    Turn a single PDF payload into a list of row dicts (one per question).

    This version is more defensive:
    - Uses month_label or falls back to month.
    - Handles missing department/production safely.
    - Uses response_value from the embedded questions.
    - Only fills score fields if they actually exist.
    """
    meta = payload.get("meta", {}) or {}
    scores = payload.get("scores", {}) or {}
    questions = payload.get("questions", []) or []

    # Meta fields (robust fallbacks)
    month = meta.get("month")
    month_label = meta.get("month_label") or month
    department = meta.get("department") or meta.get("dept_label") or ""
    production = meta.get("production") or meta.get("programme") or ""
    staff_name = meta.get("staff_name") or ""
    role = meta.get("role") or ""
    show_key = meta.get("show_key") or ""

    # Score dicts (may be missing or all None)
    scores = payload.get("scores", {}) or {}
    overall_score_default = scores.get("overall_score")
    pillar_scores = scores.get("pillar_scores") or {}
    question_scores = scores.get("question_scores") or {}

    rows: List[Dict[str, Any]] = []

    for q in questions:
        strategic_pillar = q.get("strategic_pillar")
        qid = q.get("question_id")

        # Prefer per-row scores embedded in the question itself; fall back to summary maps
        row_overall = q.get("overall_score", overall_score_default)
        row_pillar = q.get("pillar_score")
        if row_pillar is None and strategic_pillar and pillar_scores:
            row_pillar = pillar_scores.get(str(strategic_pillar))

        row_question_score = q.get("question_score")
        if row_question_score is None and question_scores:
            row_question_score = question_scores.get(str(qid))

        row: Dict[str, Any] = {
            "source_file": source_name,
            "schema_version": payload.get("schema_version"),

            # Meta
            "month": month,
            "month_label": month_label,
            "department": department,
            "production": production,
            "staff_name": staff_name,
            "role": role,
            "show_key": show_key,

            # Scores
            "overall_score": row_overall,
            "pillar_score": row_pillar,
            "question_score": row_question_score,

            # Question-level info
            "question_id": qid,
            "question_text": q.get("question_text") or q.get("question") or "",
            "strategic_pillar": strategic_pillar or "",
            "metric": q.get("metric") or "",
            "display_order": q.get("display_order"),

            # Responses
            "response_value": q.get("response_value") or "",
            "response_type": q.get("response_type") or "",
            "notes": q.get("notes") or "",
        }

        rows.append(row)

    return rows


# ─────────────────────────────────────────────────────────────────────────────
# 1. Upload PDFs
# ─────────────────────────────────────────────────────────────────────────────
uploaded_files = st.file_uploader(
    "Upload scorecard PDFs",
    type=["pdf"],
    accept_multiple_files=True,
)

if not uploaded_files:
    st.stop()


# ─────────────────────────────────────────────────────────────────────────────
# 2. Extract JSON from each PDF and flatten
# ─────────────────────────────────────────────────────────────────────────────
all_rows: List[Dict[str, Any]] = []

for f in uploaded_files:
    reader = PdfReader(f)
    info = reader.metadata or {}
    subject = getattr(info, "subject", None) or info.get("/Subject") or ""

    if JSON_PREFIX not in subject:
        st.warning(f"No embedded data found in {f.name}, skipping.")
        continue

    _, json_str = subject.split(JSON_PREFIX, 1)
    payload = json.loads(json_str)

    rows = flatten_payload_to_rows(payload, f.name)
    all_rows.extend(rows)

if not all_rows:
    st.error("No usable data found in the uploaded PDFs.")
    st.stop()


# ─────────────────────────────────────────────────────────────────────────────
# 3. Combined table
# ─────────────────────────────────────────────────────────────────────────────
df = pd.DataFrame(all_rows)

st.subheader("Combined data")
st.dataframe(df, use_container_width=True)


# ─────────────────────────────────────────────────────────────────────────────
# 4. Simple aggregates (you can build on this later)
# ─────────────────────────────────────────────────────────────────────────────
if "overall_score" in df.columns:
    st.subheader("Average overall score by department")
    avg_dep = (
        df.groupby("department", dropna=False)["overall_score"]
        .mean()
        .reset_index()
    )
    st.dataframe(avg_dep, use_container_width=True)

if {"department", "strategic_pillar", "pillar_score"}.issubset(df.columns):
    st.subheader("Average pillar score by department")
    avg_pillar = (
        df.groupby(["department", "strategic_pillar"], dropna=False)["pillar_score"]
        .mean()
        .reset_index()
    )
    st.dataframe(avg_pillar, use_container_width=True)


# ─────────────────────────────────────────────────────────────────────────────
# 5. Placeholder for AI interpretation
# ─────────────────────────────────────────────────────────────────────────────
st.subheader("AI Overall Interpretation")

if st.button("Generate AI summary"):
    st.write("Here we will call the AI to summarise the combined results...")
    # Later: plug in your OpenAI call here
